{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1",
   "display_name": "Python 3.8.5 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Embedding, GRU, Dense\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "source": [
    "Finte State Machine for Reber Grammar   \n",
    "   \n",
    "![Reber Grammar](Images/reber.gif \"Reber Grammar\")"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reber_grammar = [\n",
    "    [(\"B\", 1)],           \n",
    "    [(\"T\", 2), (\"P\", 3)], \n",
    "    [(\"S\", 2), (\"X\", 4)], \n",
    "    [(\"T\", 3), (\"V\", 5)], \n",
    "    [(\"X\", 3), (\"S\", 6)],\n",
    "    [(\"P\", 4), (\"V\", 6)],\n",
    "    [(\"E\", None)]]        "
   ]
  },
  {
   "source": [
    "Finite State Machine for Embedded Reber Grammar   \n",
    "   \n",
    "![Embedded Reber Grammar](Images/emb_reber.gif \"Embedded Reber Grammar\")"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_reber_grammar = [\n",
    "    [(\"B\", 1)],\n",
    "    [(\"T\", 2), (\"P\", 3)],\n",
    "    [(reber_grammar, 4)],\n",
    "    [(reber_grammar, 5)],\n",
    "    [(\"T\", 6)],\n",
    "    [(\"P\", 6)],\n",
    "    [(\"E\", None)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function generates strings based on the (Embedded) Reber Grammar\n",
    "def generate(grammar):\n",
    "    state, output = 0, []\n",
    "    while state is not None:\n",
    "        index = np.random.randint(len(grammar[state]))\n",
    "        production, state = grammar[state][index]\n",
    "        if isinstance(production, list):\n",
    "            production = generate(grammar=production)\n",
    "        output.append(production)\n",
    "    return \"\".join(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "BTXXTTVPXTVPXTTVPSE BPVPSE BTXSE BPVVE BPVVE BTSXSE BPTVPXTTTVVE BPVVE BTXSE BTXXVPSE BPTTTTTTTTVVE BTXSE BPVPSE BTXSE BPTVPSE BTXXTVPSE BPVVE BPVVE BPVVE BPTTVVE BPVVE BPVVE BTXXVVE BTXXVVE BTXXVPXVVE BTXSE BPTTTTTTTTTVPSE BPVPXTTVPXTTTVPSE BTXXTVVE BPTVPXVVE "
     ]
    }
   ],
   "source": [
    "for _ in range(30):\n",
    "    print(generate(reber_grammar), end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "BPBPVVEPE BPBPTVPSEPE BPBTXXVVEPE BTBPTVPXVVETE BTBPVVETE BTBTSSSSSSSXXVVETE BPBTSSSXXTTTTVPSEPE BTBPTTVVETE BPBTXXTVVEPE BTBTXSETE BPBTSSSSSXXTTVPXVPXTTTVVEPE BPBTSSXXTVPSEPE BPBPTTTTTTTVPSEPE BTBTSXSETE BPBPTVPXVVEPE BPBPVVEPE BPBPTVVEPE BTBPTTVPXTTVPSETE BTBTSSXSETE BTBTXXTTVVETE "
     ]
    }
   ],
   "source": [
    "for _ in range(20):\n",
    "    print(generate(embedded_reber_grammar), end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "POSSIBLE_CHARS = \"BEPSTVX\"\n",
    "\n",
    "# This function generate strings that do not respect the grammar\n",
    "# We generate a string that respects the grammar, and we will corrupt it by changing just one character\n",
    "def generate_corrupted(grammar, chars=POSSIBLE_CHARS):\n",
    "    good_string = generate(grammar)\n",
    "    index = np.random.randint(len(good_string))\n",
    "    good_char = good_string[index]\n",
    "    bad_char = np.random.choice(sorted(set(chars) - set(good_char)))\n",
    "    return good_string[:index] + bad_char + good_string[index + 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "BTBTXPETE BTBTSSSXXTTVSXVPXTTTVVETE BTBXTTVPSETE BEBTSSSSSXXVPXTVVETE BTBXTTVVETE BPBTXSTPE BTBTXXTTTVPSBTE BTBTXSETX BTBTSXSSTE BPBPVVEPT BTBPTVEETE BTBTSSXXTTVXETE BTBTSXTTVVETE BPBPVVTPE BTBTSXTTVVETE EPBPVPXVVEPE BPTTXSEPE BPBTXXSPXTVVEPE BTBTXSPTE BPTTSXXTVPXVVEPE "
     ]
    }
   ],
   "source": [
    "for _ in range(20):\n",
    "    print(generate_corrupted(embedded_reber_grammar), end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to embed input strings\n",
    "def str_to_ids(s, chars=POSSIBLE_CHARS):\n",
    "    return [chars.index(c) for c in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate 50% good and 50% bad strings\n",
    "def generate_dataset(size):\n",
    "    good_strings = [string_to_ids(generate(embedded_reber_grammar))\n",
    "                    for _ in range(size // 2)]\n",
    "    bad_strings = [string_to_ids(generate_corrupted(embedded_reber_grammar))\n",
    "                   for _ in range(size - size // 2)]\n",
    "    all_strings = good_strings + bad_strings\n",
    "    X = tf.ragged.constant(all_strings, ragged_rank=1)\n",
    "    y = np.array([[1.] for _ in range(len(good_strings))] +\n",
    "                 [[0.] for _ in range(len(bad_strings))])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = generate_dataset(10000)\n",
    "X_valid, y_valid = generate_dataset(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(16,), dtype=int32, numpy=array([0, 4, 0, 4, 3, 3, 6, 6, 5, 2, 6, 5, 5, 1, 4, 1], dtype=int32)>,\n",
       " array([1.]))"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "X_train[0], y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "/home/prateekd007/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential/gru/RaggedToTensor/boolean_mask_1/GatherV2:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential/gru/RaggedToTensor/boolean_mask/GatherV2:0\", shape=(None, 5), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential/gru/RaggedToTensor/Shape:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "313/313 [==============================] - 6s 14ms/step - loss: 0.6931 - accuracy: 0.5033 - val_loss: 0.6794 - val_accuracy: 0.5690\n",
      "Epoch 2/20\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.6725 - accuracy: 0.5553 - val_loss: 0.6510 - val_accuracy: 0.6205\n",
      "Epoch 3/20\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.6514 - accuracy: 0.5797 - val_loss: 0.6408 - val_accuracy: 0.6175\n",
      "Epoch 4/20\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.6361 - accuracy: 0.5904 - val_loss: 0.6079 - val_accuracy: 0.6455\n",
      "Epoch 5/20\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.5967 - accuracy: 0.6529 - val_loss: 0.5482 - val_accuracy: 0.7100\n",
      "Epoch 6/20\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.5279 - accuracy: 0.7209 - val_loss: 0.4730 - val_accuracy: 0.7045\n",
      "Epoch 7/20\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.3738 - accuracy: 0.8425 - val_loss: 0.3198 - val_accuracy: 0.8755\n",
      "Epoch 8/20\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.2760 - accuracy: 0.8940 - val_loss: 0.2396 - val_accuracy: 0.9135\n",
      "Epoch 9/20\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.1843 - accuracy: 0.9382 - val_loss: 0.1212 - val_accuracy: 0.9600\n",
      "Epoch 10/20\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.1174 - accuracy: 0.9679 - val_loss: 0.0613 - val_accuracy: 0.9875\n",
      "Epoch 11/20\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.0428 - accuracy: 0.9895 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 9.3057e-04 - accuracy: 1.0000 - val_loss: 7.6823e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 7.1426e-04 - accuracy: 1.0000 - val_loss: 6.2507e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 5.7376e-04 - accuracy: 1.0000 - val_loss: 5.2503e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 4.8402e-04 - accuracy: 1.0000 - val_loss: 4.6437e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 4.1212e-04 - accuracy: 1.0000 - val_loss: 4.0763e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 3.5418e-04 - accuracy: 1.0000 - val_loss: 3.6713e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 3.0436e-04 - accuracy: 1.0000 - val_loss: 3.3723e-04 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 5\n",
    "\n",
    "model = Sequential([\n",
    "    InputLayer(input_shape=[None], dtype=tf.int32, ragged=True),\n",
    "    Embedding(input_dim=len(POSSIBLE_CHARS), output_dim=embedding_size),\n",
    "    GRU(30),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "optimizer = SGD(lr=0.02, momentum=0.95, nesterov=True)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Estimated probability that these are Reber strings:\nBPBTSSSSSSSXXTTVPXVPXTTTTTVVETE: 1.77%\nBPBTSSSSSSSXXTTVPXVPXTTTTTVVEPE: 99.95%\n"
     ]
    }
   ],
   "source": [
    "test_strings = [\n",
    "    \"BPBTSSSSSSSXXTTVPXVPXTTTTTVVETE\",\n",
    "    \"BPBTSSSSSSSXXTTVPXVPXTTTTTVVEPE\"\n",
    "]\n",
    "X_test = tf.ragged.constant([string_to_ids(s) for s in test_strings], ragged_rank=1)\n",
    "\n",
    "y_proba = model.predict(X_test)\n",
    "print(\"Estimated probability that these are Reber strings:\")\n",
    "for index, string in enumerate(test_strings):\n",
    "    print(\"{}: {:.2f}%\".format(string, 100 * y_proba[index][0]))"
   ]
  },
  {
   "source": [
    "Our RNN identifies the pattern  of Embedded Reber Grammar i.e. the second letter should always be equal to the second to last letter with  very high proabability. That requires a fairly long short-term memory."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}
